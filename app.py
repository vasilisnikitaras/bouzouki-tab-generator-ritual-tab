# ğŸ“¦ Î•Î¹ÏƒÎ±Î³Ï‰Î³Î® Î±Ï€Î±ÏÎ±Î¯Ï„Î·Ï„Ï‰Î½ Î²Î¹Î²Î»Î¹Î¿Î¸Î·ÎºÏÎ½
import streamlit as st
import matplotlib.pyplot as plt
import numpy as np
import yt_dlp
import librosa
import soundfile as sf
import os
import re
from fpdf import FPDF
from mido import Message, MidiFile, MidiTrack
from datetime import datetime
import librosa.display

# ğŸ¼ ÎŸÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î²Î¬ÏƒÎµÏ‰Î½ Ï‡Î¿ÏÎ´ÏÎ½ Î³Î¹Î± Ï„Î¿ Ï„ÎµÏ„ÏÎ¬Ï‡Î¿ÏÎ´Î¿ Î¼Ï€Î¿Ï…Î¶Î¿ÏÎºÎ¹
string_bases = {'ÎÏ„Î¿': 48, 'Î¦Î±': 53, 'Î›Î±': 57, 'Î¡Îµ': 62}
note_names = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']

# ğŸ” ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® ÏƒÏ…Ï‡Î½ÏŒÏ„Î·Ï„Î±Ï‚ ÏƒÎµ MIDI Î±ÏÎ¹Î¸Î¼ÏŒ
def freq_to_midi(freq):
    return int(round(69 + 12 * np.log2(freq / 440.0)))

# ğŸ” ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® Î½ÏŒÏ„Î±Ï‚ ÏƒÎµ MIDI Î±ÏÎ¹Î¸Î¼ÏŒ (Î¼Îµ Î­Î»ÎµÎ³Ï‡Î¿ ÎµÎ³ÎºÏ…ÏÏŒÏ„Î·Ï„Î±Ï‚)
def note_to_midi(note):
    match = re.match(r'^([A-G]#?|[A-G]b?)(-?\d+)$', note.strip())
    if not match:
        raise ValueError(f"ÎœÎ· Î­Î³ÎºÏ…ÏÎ· Î½ÏŒÏ„Î±: {note}")
    name, octave = match.groups()
    octave = int(octave)
    return note_names.index(name) + 12 * (octave + 1)

# ğŸ” ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® MIDI Î±ÏÎ¹Î¸Î¼Î¿Ï ÏƒÎµ Î½ÏŒÏ„Î± (Ï€.Ï‡. A4)
def midi_to_note(midi):
    name = note_names[midi % 12]
    octave = midi // 12 - 1
    return f"{name}{octave}"

# ğŸ” ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® MIDI ÏƒÎµ ÏƒÏ…Ï‡Î½ÏŒÏ„Î·Ï„Î± (Hz)
def midi_to_freq(midi):
    return round(440 * 2 ** ((midi - 69) / 12), 2)

# ğŸ¯ Î•ÏÏÎµÏƒÎ· Î¸Î­ÏƒÎµÏ‰Î½ (Ï‡Î¿ÏÎ´Î® ÎºÎ±Î¹ Ï„Î¬ÏƒÏ„Î¿) Î³Î¹Î± ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î¿ MIDI
def find_positions(midi):
    return [(s, midi - b) for s, b in string_bases.items() if 0 <= midi - b <= 12]

# ğŸ¨ Î£Ï‡ÎµÎ´Î¯Î±ÏƒÎ· Î¸Î­ÏƒÎµÏ‰Î½ ÏƒÏ„Î¿ Î¼Î±Î½Î¯ÎºÎ¹ Ï„Î¿Ï… Î¼Ï€Î¿Ï…Î¶Î¿Ï…ÎºÎ¹Î¿Ï
def plot_positions(midi):
    positions = find_positions(midi)
    fig, ax = plt.subplots(figsize=(10, 4))
    strings = list(string_bases.keys())
    ax.set_yticks(range(len(strings)))
    ax.set_yticklabels(strings)
    ax.set_xticks(range(13))
    ax.set_xlim(-0.5, 12.5)
    ax.set_ylim(-0.5, len(strings) - 0.5)
    ax.grid(True)
    for s, f in positions:
        y = strings.index(s)
        ax.plot(f, y, 'ro', markersize=12)
        ax.text(f, y + 0.2, midi_to_note(midi), ha='center')
    st.pyplot(fig)

# ğŸ§  Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Ï„Î±Î¼Ï€Î»Î±Ï„Î¿ÏÏÎ±Ï‚ Î±Ï€ÏŒ Î»Î¯ÏƒÏ„Î± Î½Î¿Ï„ÏÎ½ ÎºÎ±Î¹ Î´Î¹Î¬ÏÎºÎµÎ¹Î±Ï‚
def tab_from_notes(note_list):
    tab = []
    for note, dur in note_list:
        midi = note_to_midi(note)
        pos = find_positions(midi)
        if pos:
            s, f = pos[0]
            tab.append({'ÎÏŒÏ„Î±': note, 'Î§Î¿ÏÎ´Î®': s, 'Î¤Î¬ÏƒÏ„Î¿': f, 'Î”Î¹Î¬ÏÎºÎµÎ¹Î±': dur})
        else:
            tab.append({'ÎÏŒÏ„Î±': note, 'Î§Î¿ÏÎ´Î®': 'â€”', 'Î¤Î¬ÏƒÏ„Î¿': 'â€”', 'Î”Î¹Î¬ÏÎºÎµÎ¹Î±': dur})
    return tab

# ğŸ–¼ï¸ Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± ÎµÎ¹ÎºÏŒÎ½Î±Ï‚ Î¼Îµ Ï„Î¹Ï‚ Î¸Î­ÏƒÎµÎ¹Ï‚ ÏƒÏ„Î¿ Î¼Î±Î½Î¯ÎºÎ¹
def generate_fretboard_image(tab):
    fig, ax = plt.subplots(figsize=(10, 2))
    strings = list(string_bases.keys())
    ax.set_yticks(range(len(strings)))
    ax.set_yticklabels(strings)
    ax.set_xticks(range(13))
    ax.set_xlim(-0.5, 12.5)
    ax.set_ylim(-0.5, len(strings) - 0.5)
    ax.grid(True)
    for t in tab:
        if t['Î¤Î¬ÏƒÏ„Î¿'] != 'â€”':
            y = strings.index(t['Î§Î¿ÏÎ´Î®'])
            ax.plot(t['Î¤Î¬ÏƒÏ„Î¿'], y, 'ro', markersize=10)
            ax.text(t['Î¤Î¬ÏƒÏ„Î¿'], y + 0.2, t['ÎÏŒÏ„Î±'], ha='center', fontsize=8)
    image_path = "fretboard.png"
    fig.savefig(image_path, bbox_inches='tight')
    plt.close(fig)
    return image_path

# ğŸ“„ Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± PDF Î¼Îµ Ï„Î±Î¼Ï€Î»Î±Ï„Î¿ÏÏÎ± ÎºÎ±Î¹ ÎµÎ¾ÏÏ†Ï…Î»Î»Î¿
def generate_pdf(tab):
    pdf = FPDF()
    pdf.add_page()
    pdf.set_font("Arial", size=12)
    pdf.cell(200, 10, txt="ğŸ¼ Î¤ÎµÎ»ÎµÏ„Î¿Ï…ÏÎ³Î¹ÎºÎ® Î¤Î±Î¼Ï€Î»Î±Ï„Î¿ÏÏÎ± Î³Î¹Î± Î¤ÎµÏ„ÏÎ¬Ï‡Î¿ÏÎ´Î¿ ÎœÏ€Î¿Ï…Î¶Î¿ÏÎºÎ¹", ln=True, align='C')
    pdf.ln(10)
    for t in tab:
        line = f"{t['ÎÏŒÏ„Î±']} â†’ Î§Î¿ÏÎ´Î®: {t['Î§Î¿ÏÎ´Î®']}, Î¤Î¬ÏƒÏ„Î¿: {t['Î¤Î¬ÏƒÏ„Î¿']}, Î”Î¹Î¬ÏÎºÎµÎ¹Î±: {t['Î”Î¹Î¬ÏÎºÎµÎ¹Î±']}"
        pdf.cell(200, 10, txt=line, ln=True)
    pdf.ln(10)
    pdf.set_font("Arial", style='B', size=14)
    pdf.cell(200, 10, txt="ğŸ“„ Î•Î¾ÏÏ†Ï…Î»Î»Î¿", ln=True, align='C')
    pdf.set_font("Arial", size=12)
    pdf.cell(200, 10, txt=f"Î¤Î¯Ï„Î»Î¿Ï‚: Î¤ÎµÎ»ÎµÏ„Î¿Ï…ÏÎ³Î¹ÎºÎ® Î¤Î±Î¼Ï€Î»Î±Ï„Î¿ÏÏÎ±", ln=True, align='L')
    pdf.cell(200, 10, txt=f"Î—Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î±: {datetime.now().strftime('%d/%m/%Y')}", ln=True, align='L')
    pdf.cell(200, 10, txt="Î¥Ï€Î¿Î³ÏÎ±Ï†Î®: Î’Î±ÏƒÎ¯Î»Î·Ï‚", ln=True, align='L')
    image_path = generate_fretboard_image(tab)
    pdf.image(image_path, x=10, y=pdf.get_y(), w=180)
    pdf.output("tab.pdf")
    return "tab.pdf"

# ğŸ¹ Î•Î¾Î±Î³Ï‰Î³Î® MIDI Î±ÏÏ‡ÎµÎ¯Î¿Ï… Î±Ï€ÏŒ Ï„Î·Î½ Ï„Î±Î¼Ï€Î»Î±Ï„Î¿ÏÏÎ±
def export_midi(tab, filename="output.mid"):
    mid = MidiFile()
    track = MidiTrack()
    mid.tracks.append(track)
    time_unit = 480
    for t in tab:
        try:
            midi = note_to_midi(t['ÎÏŒÏ„Î±'])
            duration = int(t['Î”Î¹Î¬ÏÎºÎµÎ¹Î±'] * time_unit)
            track.append(Message('note_on', note=midi, velocity=64, time=0))
            track.append(Message('note_off', note=midi, velocity=64, time=duration))
        except:
            continue
    mid.save(filename)
    return filename

# ğŸ“ˆ Î¦Î±ÏƒÎ¼Î±Ï„Î¹ÎºÎ® Î±Î½Î¬Î»Ï…ÏƒÎ· Î±ÏÏ‡ÎµÎ¯Î¿Ï… Î®Ï‡Î¿Ï…
def plot_spectrum(file_path):
    y, sr = librosa.load(file_path)
    D = np.abs(librosa.stft(y))**2
    S = librosa.feature.melspectrogram(S=D, sr=sr)
    fig, ax = plt.subplots(figsize=(10, 4))
    img = librosa.display.specshow(librosa.power_to_db(S, ref=np.max), sr=sr, x_axis='time', y_axis='mel')
    ax.set_title("ğŸ“ˆ Î¦Î±ÏƒÎ¼Î±Ï„Î¹ÎºÎ® Î‘Î½Î¬Î»Ï…ÏƒÎ·")
    fig.colorbar(img, ax=ax, format="%+2.0f dB")
    st.pyplot(fig)

# ğŸ“¥ Î›Î®ÏˆÎ· Î®Ï‡Î¿Ï… Î±Ï€ÏŒ YouTube Ï‰Ï‚ WAV
def download_youtube_audio(url):
    ydl_opts = {
        'format': 'bestaudio/best',
        'outtmpl': 'audio.%(ext)s',
        'ffmpeg_location': r'C:\Users\Admin\Downloads\ffmpeg\bin',
        'postprocessors': [{
            'key': 'FFmpegExtractAudio',
            'preferredcodec': 'wav',
            'preferredquality': '192',
        }],
        'quiet': True
    }
    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        ydl.download([url])
    return 'audio.wav'

# ğŸµ Î•Î¾Î±Î³Ï‰Î³Î® Î½Î¿Ï„ÏÎ½ Î±Ï€ÏŒ Î±ÏÏ‡ÎµÎ¯Î¿ Î®Ï‡Î¿Ï…
def extract_notes_from_audio(file_path):
    y, sr = librosa.load(file_path)
    pitches, magnitudes = librosa.piptrack(y=y, sr=sr)
    notes = []
    for i in range(pitches.shape[1]):
            note = librosa.hz_to_note(pitch)
            notes.append(note)
    return notes[:20]

def extract_notes_from_audio(file_path):
    y, sr = librosa.load(file_path)
    pitches, magnitudes = librosa.piptrack(y=y, sr=sr)
    notes = []
    for i in range(pitches.shape[1]):
        index = magnitudes[:, i].argmax()
        pitch = pitches[index, i]
        if pitch > 0:
            note = librosa.hz_to_note(pitch)
            notes.append(note)
    return notes[:20]

